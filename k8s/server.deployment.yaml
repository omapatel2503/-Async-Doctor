apiVersion: apps/v1
kind: Deployment
metadata:
  name: server
  namespace: async-doctor
  labels: { app: async-doctor, tier: server }
spec:
  replicas: 1
  selector: { matchLabels: { app: async-doctor, tier: server } }
  template:
    metadata:
      labels: { app: async-doctor, tier: server }
    spec:
      containers:
        - name: server
          image: REG-docker.pkg.dev/PROJ/REPO/server:SHORT_SHA
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 4000
          envFrom:
            - configMapRef: { name: server-config }
            - secretRef:    { name: ollama-secret }
          env:
            - name: OLLAMA_API_KEY
              valueFrom:
                secretKeyRef: { name: ollama-secret, key: OLLAMA_API_KEY }
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef: { name: ollama-secret, key: DATABASE_URL }
          # Health probes (what the LB and HPA rely on during scale)
          livenessProbe:
            httpGet: { path: /api/health, port: 4000 }
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 2
            failureThreshold: 3
          readinessProbe:
            httpGet: { path: /api/health, port: 4000 }
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 2
            failureThreshold: 3
          # optional but helpful if startup is heavy
          startupProbe:
            httpGet: { path: /api/health, port: 4000 }
            failureThreshold: 30
            periodSeconds: 3
          volumeMounts:
            - name: jobs
              mountPath: /app/jobs
          resources:
            requests: { cpu: "250m", memory: "512Mi" }
            limits:   { cpu: "1000m", memory: "1Gi" }
      volumes:
        - name: jobs
          persistentVolumeClaim:
            claimName: jobs-pvc
